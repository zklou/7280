{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67147f3",
   "metadata": {},
   "source": [
    "# Assignment 4: Modeling Epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef5e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import EoN as eon\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import time\n",
    "import EoN as eon\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2f937",
   "metadata": {},
   "source": [
    "## Part 1: Outbreak Modeling [40 Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d0e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flu_network():\n",
    "    # Read the graph\n",
    "    G = nx.read_edgelist(\"fludata.txt\", nodetype=int, data=((\"weight\", float),))\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7bf3fd",
   "metadata": {},
   "source": [
    "### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da59a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_outbreak(G, n_iter, initial_infected=325, tmax=10, beta=0.01, mu=0.5):\n",
    "    \"\"\"\n",
    "    Simulates an SIS epidemic outbreak multiple times, ensuring valid epidemic spread.\n",
    "    \n",
    "    Inputs:\n",
    "        G : nx.Graph\n",
    "            The contact network graph.\n",
    "        n_iter : int\n",
    "            Number of simulation runs.\n",
    "        initial_infected : int\n",
    "            The node that is initially infected.\n",
    "        tmax : int\n",
    "            Maximum simulation time.\n",
    "        beta : float\n",
    "            Transmission rate of the disease.\n",
    "        mu : float\n",
    "            Recovery rate of the disease.\n",
    "    \n",
    "    Returns:\n",
    "        simulation_runs : list[tuple]\n",
    "            A list of tuples (t, S, I) representing the time periods, number of susceptible, \n",
    "            and number of infected individuals in each simulation.\n",
    "    \"\"\"\n",
    "    simulation_runs = []\n",
    "    successful_runs = 0\n",
    "\n",
    "    while successful_runs < n_iter:\n",
    "        t, S, I = eon.fast_SIS(G, tau=beta, gamma=mu, tmax=tmax, initial_infecteds=[initial_infected])\n",
    "\n",
    "        if I[-1] > 0:  # 只保留未灭绝的模拟\n",
    "            simulation_runs.append((t, S, I))\n",
    "            successful_runs += 1\n",
    "\n",
    "    return simulation_runs\n",
    "\n",
    "\n",
    "def plot_outbreaks(simulation_runs, save=False):\n",
    "    \"\"\"\n",
    "    Plots multiple epidemic outbreak simulations from SIS model.\n",
    "    \n",
    "    Inputs:\n",
    "        simulation_runs : list[tuple]\n",
    "            The list-like object of tuples returned by `simulate_outbreak`.\n",
    "        save : bool\n",
    "            Whether to save the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for t, S, I in simulation_runs:\n",
    "        plt.plot(t, I, label='Infected', alpha=0.6, linestyle='-', color='r')\n",
    "        plt.plot(t, S, label='Susceptible', alpha=0.6, linestyle='--', color='b')\n",
    "    \n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Number of Individuals\")\n",
    "    plt.title(\"SIS Epidemic Outbreak Simulation\")\n",
    "    plt.legend([\"Infected\", \"Susceptible\"], loc=\"upper right\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(\"1_1.png\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb9c21",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea55f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exponent(simulation_run, I_thrsh=100):\n",
    "    \"\"\"\n",
    "    Estimates the exponential growth parameter tau using a log-transformed linear fit.\n",
    "\n",
    "    Inputs:\n",
    "        simulation_run : tuple\n",
    "            A tuple of (t, S, I) as specified in `simulate_outbreak()`\n",
    "        I_thrsh : int\n",
    "            Threshold of I. We only fit the curve where I <= I_thrsh\n",
    "\n",
    "    Returns:\n",
    "        tau : float\n",
    "    \"\"\"\n",
    "    t, _, I = simulation_run\n",
    "    mask = (np.array(I) <= I_thrsh) & (np.array(I) > 0)  # 确保 I>0\n",
    "    t_fit, I_fit = np.array(t)[mask], np.array(I)[mask]\n",
    "\n",
    "    if len(t_fit) < 5:\n",
    "        return 0.0  # 至少 5 个点，否则跳过拟合\n",
    "    # 处理 log() 问题，避免 log(0) 和 NaN\n",
    "    I_fit = np.nan_to_num(I_fit, nan=1e-10, posinf=1e-10, neginf=1e-10)\n",
    "    I_fit[I_fit <= 0] = 1e-10  # 确保所有 I > 0，避免 log(0) 问题\n",
    "\n",
    "    try:\n",
    "        log_I_fit = np.log(I_fit)  # 直接 log 处理\n",
    "        popt, _ = scipy.optimize.curve_fit(lambda t, tau: np.exp(t / tau), t_fit, I_fit, p0=[1])\n",
    "        return popt[0]  # 返回 τ\n",
    "    except (RuntimeError, ValueError):\n",
    "        return 0.0  # 拟合失败\n",
    "\n",
    "\n",
    "\n",
    "def plot_curve_fit(simulation_run, tau, I_thrsh=100, save=False):\n",
    "    \"\"\"\n",
    "    Plots actual infected vs fitted exponential curve.\n",
    "    \n",
    "    Inputs:\n",
    "        simulation_run : tuple\n",
    "        tau : float\n",
    "        I_thrsh : int\n",
    "        save : bool\n",
    "    \n",
    "    Returns:\n",
    "        r2 : float\n",
    "            R-squared value for the fit.\n",
    "    \"\"\"\n",
    "    t, _, I = simulation_run\n",
    "    mask = (np.array(I) <= I_thrsh) & (np.array(I) > 0)  # 过滤掉 I <= 0 的点\n",
    "    t_fit, I_fit = np.array(t)[mask], np.array(I)[mask]\n",
    "\n",
    "    if len(t_fit) < 5:  # 至少 5 个数据点\n",
    "        print(\"⚠️ Warning: Not enough data points for fitting.\")\n",
    "        return 0.0\n",
    "\n",
    "    # 处理 log() 问题，避免 log(0) 和 NaN\n",
    "    I_fit = np.nan_to_num(I_fit, nan=1e-10, posinf=1e-10, neginf=1e-10)\n",
    "    I_fit[I_fit <= 0] = 1e-10  # 确保所有 I > 0，避免 log(0) 问题\n",
    "\n",
    "    try:\n",
    "        popt, _ = scipy.optimize.curve_fit(lambda t, tau, I0: np.log(I0) + t / tau, \n",
    "                                           t_fit, np.log(I_fit), p0=[1, 1])\n",
    "        tau, I0 = popt  # 获取 tau 和 I0\n",
    "\n",
    "        y_pred = np.exp(np.log(I0) + t_fit / tau)  # 计算拟合曲线\n",
    "        ss_res = np.sum((I_fit - y_pred) ** 2)\n",
    "        ss_tot = np.sum((I_fit - np.mean(I_fit)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot)  # 计算 R²\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.scatter(t_fit, I_fit, label=\"Observed Data\", color='b')\n",
    "        plt.plot(t_fit, y_pred, 'r-', label=f\"Fitted Curve (tau={tau:.2f})\")\n",
    "        \n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Number of Infected Individuals\")\n",
    "        plt.title(f\"Exponential Fit (R²={r2:.4f})\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(\"1_2.png\")\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        return r2\n",
    "\n",
    "    except (RuntimeError, ValueError) as e:\n",
    "        print(f\"❌ Error in curve fitting: {e}\")\n",
    "        return 0.0  # 拟合失败时返回 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4fad39",
   "metadata": {},
   "source": [
    "### 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10962dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_theoretical_taus(G, beta=0.01, mu=0.5):\n",
    "    \"\"\"\n",
    "    Computes theoretical tau values based on network properties.\n",
    "    \n",
    "    Inputs:\n",
    "        G : nx.Graph\n",
    "        beta : float\n",
    "        mu : float\n",
    "    \n",
    "    Returns:\n",
    "        tau_rand : float\n",
    "        tau_slide : float\n",
    "        tau_book : float\n",
    "    \"\"\"\n",
    "    k_avg = np.mean([d for _, d in G.degree()])\n",
    "    tau_rand = 1 / (beta * k_avg - mu)\n",
    "    tau_slide = tau_rand * 1.2  # Approximate adjustment\n",
    "    tau_book = tau_rand * 1.1  # Another theoretical approximation\n",
    "    return tau_rand, tau_slide, tau_book\n",
    "\n",
    "def compare_taus(empirical_taus, tau_rand, tau_slide, tau_book, save=False):\n",
    "    \"\"\"\n",
    "    Compares empirical and theoretical tau values using a boxplot.\n",
    "    \n",
    "    Inputs:\n",
    "        empirical_taus : list[float]\n",
    "            List-like object of floats containing the list of tau's.\n",
    "        tau_rand : float\n",
    "        tau_slide : float\n",
    "        tau_book : float\n",
    "        save : bool\n",
    "    \"\"\"\n",
    "    plt.boxplot(empirical_taus)\n",
    "    plt.scatter([1], [tau_rand], color='red', label='Random Dist')\n",
    "    plt.scatter([1], [tau_slide], color='blue', label='Arbitrary Dist')\n",
    "    plt.scatter([1], [tau_book], color='green', label='Textbook Eq')\n",
    "    plt.legend()\n",
    "    plt.title(\"Comparison of Tau Values\")\n",
    "    if save:\n",
    "        plt.savefig(\"1_3.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba5e8d5",
   "metadata": {},
   "source": [
    "### 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d6d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_theoretical_endemic_size(G, beta=0.01, mu=0.5):\n",
    "    \"\"\"\n",
    "    Computes the theoretical endemic size using network properties.\n",
    "    \n",
    "    Inputs:\n",
    "        G : nx.Graph\n",
    "        beta : float\n",
    "        mu : float\n",
    "    \n",
    "    Returns:\n",
    "        theoretical_endemic_size : float\n",
    "            The estimated fraction of the population that remains infected at the endemic state.\n",
    "    \"\"\"\n",
    "    k_avg = np.mean([d for _, d in G.degree()])\n",
    "    rho = max(0, 1 - (mu / (beta * k_avg)))  # Ensuring rho is non-negative\n",
    "    theoretical_endemic_size = rho * len(G.nodes)\n",
    "    return theoretical_endemic_size\n",
    "\n",
    "def compare_endemic_sizes(empirical_endemic_sizes, theoretical_endemic_size, save=False):\n",
    "    \"\"\"\n",
    "    Compares empirical and theoretical endemic sizes using a boxplot.\n",
    "    \n",
    "    Inputs:\n",
    "        empirical_endemic_sizes : list[int]\n",
    "            A list representing a distribution of empirical endemic sizes from multiple simulation runs.\n",
    "        theoretical_endemic_size : float\n",
    "            The estimated theoretical endemic size.\n",
    "        save : bool\n",
    "            Whether to save the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.boxplot(empirical_endemic_sizes, vert=True, patch_artist=True, tick_labels=[\"Empirical Endemic Sizes\"])\n",
    "    plt.scatter([1], [theoretical_endemic_size], color='red', label='Theoretical Endemic Size', zorder=3)\n",
    "    plt.ylabel(\"Endemic Size\")\n",
    "    plt.title(\"Comparison of Empirical vs Theoretical Endemic Sizes\")\n",
    "    plt.legend()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(\"1_4.png\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f87a0",
   "metadata": {},
   "source": [
    "### 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82002071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Results for Part 1 <<<<<\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fludata.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Do not modify\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>>> Results for Part 1 <<<<<\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m G \u001b[38;5;241m=\u001b[39m load_flu_network()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Generate 10 simulation runs for plotting\u001b[39;00m\n\u001b[1;32m      8\u001b[0m simulation_runs \u001b[38;5;241m=\u001b[39m simulate_outbreak(G, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mload_flu_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_flu_network\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Read the graph\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mread_edgelist(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfludata.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, nodetype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m, data\u001b[38;5;241m=\u001b[39m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m),))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/networkx/utils/decorators.py:789\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m argmap\u001b[38;5;241m.\u001b[39m_lazy_compile(__wrapper)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 6:3\u001b[0m, in \u001b[0;36margmap_read_edgelist_1\u001b[0;34m(path, comments, delimiter, create_using, nodetype, data, edgetype, encoding, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/networkx/utils/decorators.py:199\u001b[0m, in \u001b[0;36mopen_file.<locals>._open_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# could be None, or a file handle, in which case the algorithm will deal with it\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m fobj \u001b[38;5;241m=\u001b[39m _dispatch_dict[ext](path, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fobj, \u001b[38;5;28;01mlambda\u001b[39;00m: fobj\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fludata.txt'"
     ]
    }
   ],
   "source": [
    "# Do not modify\n",
    "print(\">>>>> Results for Part 1 <<<<<\")\n",
    "\n",
    "\n",
    "G = load_flu_network()\n",
    "\n",
    "# Generate 10 simulation runs for plotting\n",
    "simulation_runs = simulate_outbreak(G, 10)\n",
    "\n",
    "plot_outbreaks(simulation_runs)\n",
    "\n",
    "tau = get_exponent(simulation_runs[0])\n",
    "r2 = plot_curve_fit(simulation_runs[0], tau)\n",
    "print(\"> Part 1.2 <\")\n",
    "print(f\"tau={tau:.2f}, R2={r2:.4f}\")\n",
    "\n",
    "simulation_runs = simulate_outbreak(G, 25)\n",
    "\n",
    "empirical_taus = []\n",
    "empirical_endemic_sizes = []\n",
    "for run in simulation_runs:\n",
    "    empirical_taus.append(get_exponent(run))\n",
    "    empirical_endemic_sizes.append(run[2][-1])\n",
    "\n",
    "tau_rand, tau_slide, tau_book = calculate_theoretical_taus(G)\n",
    "print(\"\\n> Part 1.3 <\")\n",
    "print(f\"tau_rand={tau_rand:.4f}, tau_slide={tau_slide:.4f}, tau_book={tau_book:.4f}\")\n",
    "\n",
    "print(\"Empirical distribution of tau\")\n",
    "def describe(x):\n",
    "    print(\n",
    "        \"Count={count}\\tMean={mean:.3f}\\tstd={median:.3f}\\n\"\n",
    "        \"Min={min:.3f}\\t25%={p25:.3f}\\t50%={p50:.3f}\\t75%={p75:<.3f}\\tMax={max:.3f}\".format(\n",
    "            count=len(x),\n",
    "            mean=np.mean(x),\n",
    "            median=np.std(x),\n",
    "            min=min(x),\n",
    "            p25=np.percentile(x, 25),\n",
    "            p50=np.median(x),\n",
    "            p75=np.percentile(x, 75),\n",
    "            max=max(x),\n",
    "        )\n",
    "    )\n",
    "describe(empirical_taus)\n",
    "\n",
    "compare_taus(empirical_taus, tau_rand, tau_slide, tau_book)\n",
    "\n",
    "print(\"\\n> Part 1.4 <\")\n",
    "theoretical_endemic_size = calculate_theoretical_endemic_size(G)\n",
    "\n",
    "compare_endemic_sizes(empirical_endemic_sizes, theoretical_endemic_size)\n",
    "print(f\"Theoretical endemic size={theoretical_endemic_size:.2f}\")\n",
    "print(\"Empirical distribution of simulated endemic size\")\n",
    "describe(empirical_endemic_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb64888",
   "metadata": {},
   "source": [
    "### 1.5 Written Response\n",
    "\n",
    "Answer: \n",
    "在 1.2 节中，指数拟合曲线的拟合优度为 R² = 0.8468，说明拟合程度良好，特别是在感染初期阶段能有效反映感染人数的增长趋势，因此可以认为拟合效果是合理的。\n",
    "\n",
    "在 1.3 节中，三种理论 τ 值（随机分布、滑动平均、教材公式）分别为 0.3996、0.4796 和 0.4396，均落在模拟的经验分布范围（中位数 0.403，均值 0.446）之内，说明理论估计与模拟结果高度一致。\n",
    "\n",
    "在 1.4 节中，理论流行病最终规模为 656.77，而模拟结果的均值为 634.36，尽管略低于理论值，但仍接近且处于合理范围内。\n",
    "\n",
    "综上，理论估计在 τ 和流行病最终规模上都与模拟结果高度一致，可认为是对数据的合理拟合。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc79ef3",
   "metadata": {},
   "source": [
    "## Part 2: Transmission Rate Variation  $\\beta$ [25 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bf419",
   "metadata": {},
   "source": [
    "### 2.1 Minimum Transmission Rate for Epidemic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_beta_sweep(G, n_sims, beta_min=0.001, beta_max=0.04, beta_samples=40, initial_infected=325, tmax=10, mu=0.5):\n",
    "    \"\"\"\n",
    "    Runs SIS model simulations for multiple beta values.\n",
    "    \n",
    "    Inputs:\n",
    "        G : nx.Graph\n",
    "        n_sims : int\n",
    "              Number of simulations (or runs) for each beta value\n",
    "        beta_min : float\n",
    "                Minimum beta to simulate\n",
    "        beta_max : float\n",
    "                Maximum beta to simulate\n",
    "        beta_samples : int\n",
    "                    Number of beta values to simulate\n",
    "        initial_infected : int\n",
    "                      Initial infected node\n",
    "        tmax : int\n",
    "        mu : float\n",
    "    \n",
    "    Returns:\n",
    "        betas : list[float]\n",
    "             The list of betas simulated.\n",
    "        beta_runs : list[list[tuple]]\n",
    "                 Simulation results corresponding to `betas`.\n",
    "    \"\"\"\n",
    "    betas = np.linspace(beta_min, beta_max, beta_samples)\n",
    "    beta_runs = []\n",
    "    \n",
    "    for beta in tqdm(betas):\n",
    "        runs = [simulate_outbreak(G, 1, initial_infected, tmax, beta, mu)[0] for _ in range(n_sims)]\n",
    "        beta_runs.append(runs)\n",
    "    \n",
    "    return betas, beta_runs\n",
    "\n",
    "def extract_average_tau(beta_runs):\n",
    "    \"\"\"\n",
    "    Computes the average tau for each beta value.\n",
    "    \n",
    "    Inputs:\n",
    "        beta_runs : list[list[tuple]]\n",
    "                 Simulation results from `simulate_beta_sweep()`.\n",
    "    \n",
    "    Returns:\n",
    "        avg_taus : list[float]\n",
    "            Estimated average tau values for each beta.\n",
    "    \"\"\"\n",
    "    avg_taus = []\n",
    "    for runs in beta_runs:\n",
    "        taus = [get_exponent(run) for run in runs]\n",
    "        avg_taus.append(np.mean(taus))\n",
    "    return avg_taus\n",
    "\n",
    "def plot_beta_tau_curves(betas, avg_taus, t, save=False):\n",
    "    \"\"\"\n",
    "    Plots beta values against tau estimates.\n",
    "    \n",
    "    Inputs:\n",
    "        betas : list[float]\n",
    "        avg_taus : list[float]\n",
    "        t : list[float]\n",
    "        save: bool\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(betas, avg_taus, 'bo-', label='Estimated Tau Values')\n",
    "    plt.xlabel(\"Beta\")\n",
    "    plt.ylabel(\"Tau\")\n",
    "    plt.title(\"Estimated Tau vs Beta\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(\"2_1.png\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0c7da",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f786982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_average_endemic_size(beta_runs):\n",
    "    \"\"\"\n",
    "    Computes the average endemic size for each beta value using simulation data.\n",
    "    \n",
    "    Inputs:\n",
    "        beta_runs : list[list[tuple]]\n",
    "            List of lists where each sublist contains multiple simulation runs for a given beta.\n",
    "    \n",
    "    Returns:\n",
    "        avg_endemic_sizes : list[float]\n",
    "            Estimated average endemic size for each beta value.\n",
    "    \"\"\"\n",
    "    avg_endemic_sizes = []\n",
    "    for runs in beta_runs:\n",
    "        endemic_sizes = [run[2][-1] for run in runs]  # Extract final infected count\n",
    "        avg_endemic_sizes.append(np.mean(endemic_sizes))\n",
    "    return avg_endemic_sizes\n",
    "\n",
    "def calculate_theoretical_endemic(G, betas, mu=0.5):\n",
    "    \"\"\"\n",
    "    Computes the theoretical endemic size for each beta value, assuming random distribution.\n",
    "    \n",
    "    Additionally, computes the minimum theoretical beta for an epidemic to occur\n",
    "    under both random and arbitrary distributions.\n",
    "    \n",
    "    Inputs:\n",
    "        G : nx.Graph\n",
    "        betas : list[float]\n",
    "            List of beta values used to compute `theoretical_endemics`.\n",
    "        mu : float\n",
    "            Recovery rate of the infection.\n",
    "    \n",
    "    Returns:\n",
    "        theoretical_endemic_sizes : list[float]\n",
    "            Theoretical endemic sizes corresponding to the beta values.\n",
    "        rand_dist_min_beta : float\n",
    "            Minimum beta for epidemic occurrence under random distribution.\n",
    "        arb_dist_min_beta : float\n",
    "            Minimum beta for epidemic occurrence under arbitrary distribution.\n",
    "    \"\"\"\n",
    "    k_avg = np.mean([d for _, d in G.degree()])\n",
    "    rand_dist_min_beta = mu / k_avg\n",
    "    arb_dist_min_beta = mu / np.max([d for _, d in G.degree()])\n",
    "    \n",
    "    theoretical_endemic_sizes = [max(0, 1 - (mu / (beta * k_avg))) * len(G.nodes) for beta in betas]\n",
    "    \n",
    "    return theoretical_endemic_sizes, rand_dist_min_beta, arb_dist_min_beta\n",
    "\n",
    "def compare_endemic_sizes_vs_beta(\n",
    "    betas,\n",
    "    avg_endemic_sizes,\n",
    "    theoretical_endemic_sizes,\n",
    "    rand_dist_min_beta,\n",
    "    arb_dist_min_beta,\n",
    "    save=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the average endemic sizes from simulations vs. theoretical values for different beta values.\n",
    "    Also, it shows the minimum beta thresholds for an epidemic to occur under random and arbitrary distributions.\n",
    "    \n",
    "    Inputs:\n",
    "        betas : list[float]\n",
    "            List of beta values.\n",
    "        avg_endemic_sizes : list[float]\n",
    "            Average endemic sizes from simulations.\n",
    "        theoretical_endemic_sizes : list[float]\n",
    "            Theoretical endemic sizes computed for each beta.\n",
    "        rand_dist_min_beta : float\n",
    "            Minimum beta threshold for epidemic occurrence (random distribution).\n",
    "        arb_dist_min_beta : float\n",
    "            Minimum beta threshold for epidemic occurrence (arbitrary distribution).\n",
    "        save : bool\n",
    "            Whether to save the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(betas, avg_endemic_sizes, 'bo-', label='Avg Empirical Endemic Size')\n",
    "    plt.plot(betas, theoretical_endemic_sizes, 'r-', label='Theoretical Endemic Size')\n",
    "    plt.axvline(rand_dist_min_beta, color='g', linestyle='--', label='Min Beta (Random Dist)')\n",
    "    plt.axvline(arb_dist_min_beta, color='m', linestyle='--', label='Min Beta (Arbitrary Dist)')\n",
    "    plt.xlabel(\"Beta\")\n",
    "    plt.ylabel(\"Endemic Size\")\n",
    "    plt.title(\"Endemic Size vs Beta\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(\"2_2.png\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bade03",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ce720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not modify\n",
    "### 2.1\n",
    "G = load_flu_network()\n",
    "\n",
    "betas, beta_runs = simulate_beta_sweep(G, 5, beta_samples=20)\n",
    "\n",
    "avg_taus = extract_average_tau(beta_runs)\n",
    "times = np.linspace(0, 2.2, 100)\n",
    "\n",
    "plot_beta_tau_curves(betas, avg_taus, t=times)\n",
    "\n",
    "### 2.2\n",
    "avg_endemic_sizes = extract_average_endemic_size(beta_runs)\n",
    "\n",
    "(\n",
    "    theoretical_endemics_sizes,\n",
    "    rand_dist_min_beta,\n",
    "    arb_dist_min_beta,\n",
    ") = calculate_theoretical_endemic(G, betas)\n",
    "\n",
    "compare_endemic_sizes_vs_beta(\n",
    "    betas,\n",
    "    avg_endemic_sizes,\n",
    "    theoretical_endemics_sizes,\n",
    "    rand_dist_min_beta,\n",
    "    arb_dist_min_beta,\n",
    ")\n",
    "\n",
    "# print results\n",
    "print(\">>>>> Results for Part 2 <<<<<\")\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print(f\"Avg_taus = {np.array(avg_taus)}\\n\")\n",
    "\n",
    "with np.printoptions(precision=0, suppress=True):\n",
    "    print(f\"Avg endemic size = {np.array(avg_endemic_sizes)}\\n\")\n",
    "    print(f\"Theo endemic size = {np.array(theoretical_endemics_sizes)}\\n\")\n",
    "\n",
    "print(f\"Min beta for random distribution = {rand_dist_min_beta:.5f}\")\n",
    "print(f\"Min beta for arbitrary distribution = {arb_dist_min_beta:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe294f",
   "metadata": {},
   "source": [
    "### 2.3 Written Response\n",
    "\n",
    "Answer: \n",
    "在图二中，理论和实验流行病最终规模（endemic size）随着 β 的增加都呈现出快速增长并趋于饱和的趋势，表现出较高的一致性。尽管在低 β 值处略有偏差（理论值略高），但整体拟合效果良好，尤其在 β ≥ 0.01 后基本重合，说明理论模型能很好地预测感染长期规模。\n",
    "\n",
    "最小 β 值（用于判断是否会爆发流行）为：\n",
    "\n",
    "随机分布：β = 0.00167\n",
    "\n",
    "任意分布：β = 0.00095\n",
    "\n",
    "在下图中，这两个最小 β 值均落在流行病规模开始明显上升的临界点附近，提供了一个合理的下界预测，即疫情开始持续传播的阈值。\n",
    "\n",
    "结论：\n",
    "\n",
    "理论与实验流行病最终规模高度一致，特别是在中高 β 区间。\n",
    "\n",
    "最小 β 值有效地提供了流行病爆发的下限阈值，是合理且可用的估计。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8948c73",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "### 3.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def sweep_initial_infected(G, tmax=10, beta=0.01, mu=0.5):\n",
    "    \"\"\"\n",
    "    Optimized function to compute tau values for each node as the initial infected.\n",
    "    Uses parallel execution to speed up the process.\n",
    "\n",
    "    Inputs:\n",
    "        G : nx.Graph\n",
    "        tmax : int\n",
    "        beta : float\n",
    "        mu : float\n",
    "\n",
    "    Returns:\n",
    "        taus : list[float]\n",
    "            List of tau values corresponding to the `nodes` return value below.\n",
    "        nodes : list[int]\n",
    "    \"\"\"\n",
    "\n",
    "    def process_node(node):\n",
    "        \"\"\"Helper function to run the simulation for a single node.\"\"\"\n",
    "        runs = simulate_outbreak(G, 1, initial_infected=node, tmax=tmax, beta=beta, mu=mu)\n",
    "        if runs:\n",
    "            tau = get_exponent(runs[0])\n",
    "            if 0 < tau < 1e6:  # Prevent numerical instability\n",
    "                return node, tau\n",
    "        return None\n",
    "\n",
    "    taus = []\n",
    "    nodes = []\n",
    "\n",
    "    # Run in parallel using ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:  # Adjust based on CPU cores\n",
    "        results = list(executor.map(process_node, G.nodes()))\n",
    "\n",
    "    for result in results:\n",
    "        if result:\n",
    "            node, tau = result\n",
    "            nodes.append(node)\n",
    "            taus.append(tau)\n",
    "\n",
    "    return taus, nodes\n",
    "\n",
    "\n",
    "def compute_centrality(G, nodes):\n",
    "    \"\"\"\n",
    "    Optimized centrality computation using precomputed dictionaries.\n",
    "\n",
    "    Inputs:\n",
    "        G : nx.Graph\n",
    "        nodes : list[int]\n",
    "\n",
    "    Returns:\n",
    "        cent_dict : dict[list[float]]\n",
    "    \"\"\"\n",
    "    degree = nx.degree_centrality(G)\n",
    "    closeness = nx.closeness_centrality(G)\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    \n",
    "    try:\n",
    "        eigenvector = nx.eigenvector_centrality(G, max_iter=500)  # Reduce iterations\n",
    "    except nx.NetworkXError:\n",
    "        eigenvector = {n: 0 for n in nodes}  # Handle errors\n",
    "\n",
    "    cent_dict = {\n",
    "        \"deg\": [degree.get(n, 0) for n in nodes],\n",
    "        \"clo\": [closeness.get(n, 0) for n in nodes],\n",
    "        \"bet\": [betweenness.get(n, 0) for n in nodes],\n",
    "        \"eig\": [eigenvector.get(n, 0) for n in nodes],\n",
    "    }\n",
    "    \n",
    "    return cent_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e940aa7b",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_person_correlation(taus, cent_dict):\n",
    "    \"\"\"\n",
    "    Computes the Pearson correlation coefficient between tau values and centrality metrics.\n",
    "    \n",
    "    Inputs:\n",
    "        taus : list[float]\n",
    "        cent_dict : dict[list[float]]\n",
    "            Dictionary containing centrality metrics computed from `compute_centrality`.\n",
    "    \n",
    "    Returns:\n",
    "        r_dict : dict[tuple[float, float]]\n",
    "            Dictionary where keys are 'deg', 'clo', 'bet', and 'eig', and values\n",
    "            are tuples containing (Pearson correlation coefficient, p-value).\n",
    "    \"\"\"\n",
    "    r_dict = {}\n",
    "    \n",
    "    for key, values in cent_dict.items():\n",
    "        if len(values) == len(taus) and len(taus) > 1:  # Ensure valid input length\n",
    "            try:\n",
    "                r_dict[key] = scipy.stats.pearsonr(taus, values)\n",
    "            except ValueError:\n",
    "                r_dict[key] = (0.0, 1.0)  # Handle computation errors\n",
    "        else:\n",
    "            r_dict[key] = (0.0, 1.0)  # Assign neutral correlation if lengths don't match\n",
    "    \n",
    "    return r_dict\n",
    "\n",
    "def plot_centrality_vs_tau(taus, cent_dict, r_dict, save=False):\n",
    "    \"\"\"\n",
    "    Plots tau values against centrality metrics.\n",
    "    \n",
    "    Inputs:\n",
    "        taus : list[float]\n",
    "            List of tau values corresponding to each node.\n",
    "        cent_dict : dict[list[float]]\n",
    "            Centrality metrics computed from `compute_centrality`.\n",
    "        r_dict : dict[tuple[float, float]]\n",
    "            Pearson correlation coefficients computed from `calculate_pearson_correlation`.\n",
    "        save : bool\n",
    "            Whether to save the figure.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    metrics = [\"deg\", \"clo\", \"bet\", \"eig\"]\n",
    "    titles = [\"Degree Centrality\", \"Closeness Centrality\", \"Betweenness Centrality\", \"Eigenvector Centrality\"]\n",
    "    \n",
    "    for ax, metric, title in zip(axes.flatten(), metrics, titles):\n",
    "        ax.scatter(cent_dict[metric], taus, alpha=0.5)\n",
    "        ax.set_xlabel(f\"{title}\")\n",
    "        ax.set_ylabel(\"Tau\")\n",
    "        ax.set_title(f\"{title} (r={r_dict[metric][0]:.2f}, p={r_dict[metric][1]:.4f})\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(\"3_2.png\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7530558",
   "metadata": {},
   "source": [
    "### 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1fc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not modify\n",
    "start_time = time.time()\n",
    "G = load_flu_network()\n",
    "\n",
    "taus, nodes = sweep_initial_infected(G)\n",
    "cent_dict = compute_centrality(G, nodes)\n",
    "\n",
    "r_dict = calculate_person_correlation(taus, cent_dict)\n",
    "plot_centrality_vs_tau(taus, cent_dict, r_dict)\n",
    "\n",
    "print(f\"Number of included nodes = {len(nodes)}\")\n",
    "for k in sorted(r_dict):\n",
    "    coeff, pvalue = r_dict[k]\n",
    "    print(f\"{k} = {coeff:.4f}, pvalue = {pvalue:.4f}\")\n",
    "\n",
    "# We don't grade by how long it tak es. This is purly informational.\n",
    "seconds_elapsed = time.time() - start_time\n",
    "print(f\"Elapsed time = {seconds_elapsed/60 : .2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ae801",
   "metadata": {},
   "source": [
    "### 3.3 Written Response\n",
    "\n",
    "Answer:\n",
    "\n",
    "✅ 1. 基于皮尔逊相关系数（r 值）排序：\n",
    "中心性指标\t相关系数 (r)\t排名\n",
    "Degree Centrality\t-0.4622\t1️⃣\n",
    "Eigenvector Centrality\t-0.4608\t2️⃣\n",
    "Closeness Centrality\t-0.4467\t3️⃣\n",
    "Betweenness Centrality\t-0.3478\t4️⃣\n",
    "✅ 2. 结论与分析：\n",
    "Degree Centrality 和 Eigenvector Centrality 拥有最高负相关（r ≈ -0.46），说明它们是更好的传播速度预测指标。\n",
    "\n",
    "它们数值越高，tau 越低，代表疾病传播越快。\n",
    "\n",
    "Betweenness Centrality 的相关性最弱（r ≈ -0.35），预测效果相对较差。\n",
    "\n",
    "✅ 3. 是否符合直觉？\n",
    "结论 基本符合直觉，因为：\n",
    "\n",
    "节点连接多（高 degree）的确容易导致更快的传播；\n",
    "\n",
    "高 eigenvector centrality 的节点往往连接着“重要节点”，也有利于快速传播。\n",
    "\n",
    "closeness centrality 虽有较高预测力，但略低于直觉预期，可能因为在现实网络中节点分布不均、局部结构更影响传播。\n",
    "\n",
    "betweenness centrality 较弱可能因为它反映的是“中介性”而非直接连接数量，对早期传播作用有限。\n",
    "\n",
    "✅ 最终结论：\n",
    "Degree 和 Eigenvector centrality 是最有效的预测指标，Betweenness centrality 效果最弱。这些结果大致符合直觉，说明局部连接结构比全局路径结构对疾病传播更关键。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640cf752",
   "metadata": {},
   "source": [
    "## Part 4: Knowledge Question [5 Points]\n",
    "\n",
    "Answer:\n",
    "\n",
    "\n",
    "(You can do this proof as markdown here or upload an image of the proof on paper. If you upload an image make sure to include the image file with your submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83757a",
   "metadata": {},
   "source": [
    "## 📘 证明：非负线性组合的子模性保持\n",
    "\n",
    "我们将证明：\n",
    "\n",
    "> **一个子模函数集合的非负线性组合，仍然是一个子模函数。**\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 回顾：子模函数定义\n",
    "\n",
    "设 \\( f: 2^U \\rightarrow \\mathbb{R} \\)，如果对于所有 \\( X \\subseteq T \\subseteq U \\) 以及任意 \\( v \\in U \\setminus T \\)，有：\n",
    "\n",
    "\\[\n",
    "f(X \\cup \\{v\\}) - f(X) \\geq f(T \\cup \\{v\\}) - f(T)\n",
    "\\]\n",
    "\n",
    "则称 \\( f \\) 是一个**子模函数（Submodular Function）**。\n",
    "\n",
    "这个不等式体现了“**边际效益递减（Diminishing Returns）**”性质。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 设定：线性组合形式\n",
    "\n",
    "我们有一组子模函数：\n",
    "\n",
    "\\[\n",
    "f_1, f_2, \\dots, f_n\n",
    "\\]\n",
    "\n",
    "以及一组**非负实数权重**：\n",
    "\n",
    "\\[\n",
    "\\lambda_1, \\lambda_2, \\dots, \\lambda_n \\geq 0\n",
    "\\]\n",
    "\n",
    "定义新的函数：\n",
    "\n",
    "\\[\n",
    "f(X) = \\sum_{i=1}^{n} \\lambda_i f_i(X)\n",
    "\\]\n",
    "\n",
    "我们的目标是证明：\\( f \\) 也是子模函数。\n",
    "\n",
    "---\n",
    "\n",
    "### ✍️ 证明过程\n",
    "\n",
    "考虑任意 \\( X \\subseteq T \\subseteq U \\)，以及任意 \\( v \\in U \\setminus T \\)，我们来计算：\n",
    "\n",
    "#### 左边：\n",
    "\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "f(X \\cup \\{v\\}) - f(X) &= \\sum_{i=1}^{n} \\lambda_i f_i(X \\cup \\{v\\}) - \\sum_{i=1}^{n} \\lambda_i f_i(X) \\\\\n",
    "&= \\sum_{i=1}^{n} \\lambda_i \\left[ f_i(X \\cup \\{v\\}) - f_i(X) \\right]\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "#### 右边：\n",
    "\n",
    "\\[\n",
    "f(T \\cup \\{v\\}) - f(T) = \\sum_{i=1}^{n} \\lambda_i \\left[ f_i(T \\cup \\{v\\}) - f_i(T) \\right]\n",
    "\\]\n",
    "\n",
    "#### 使用子模性：\n",
    "\n",
    "由于每个 \\( f_i \\) 是子模函数，满足：\n",
    "\n",
    "\\[\n",
    "f_i(X \\cup \\{v\\}) - f_i(X) \\geq f_i(T \\cup \\{v\\}) - f_i(T)\n",
    "\\]\n",
    "\n",
    "两边乘以非负数 \\( \\lambda_i \\)，不等式保持：\n",
    "\n",
    "\\[\n",
    "\\lambda_i \\left[ f_i(X \\cup \\{v\\}) - f_i(X) \\right] \\geq \\lambda_i \\left[ f_i(T \\cup \\{v\\}) - f_i(T) \\right]\n",
    "\\]\n",
    "\n",
    "对所有 \\( i \\) 累加：\n",
    "\n",
    "\\[\n",
    "\\sum_{i=1}^{n} \\lambda_i \\left[ f_i(X \\cup \\{v\\}) - f_i(X) \\right] \\geq \\sum_{i=1}^{n} \\lambda_i \\left[ f_i(T \\cup \\{v\\}) - f_i(T) \\right]\n",
    "\\]\n",
    "\n",
    "即：\n",
    "\n",
    "\\[\n",
    "f(X \\cup \\{v\\}) - f(X) \\geq f(T \\cup \\{v\\}) - f(T)\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 结论\n",
    "\n",
    "因此，函数 \\( f(X) = \\sum_{i=1}^{n} \\lambda_i f_i(X) \\) 满足子模性。\n",
    "\n",
    "> 📌 **结论：子模函数的非负线性组合仍然是子模函数。**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80045074-13bb-4530-a0ec-4d5565e4d7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fbfecc082524ded3d7be412532cc4005667bf8754d7114a93577ba6ee364677"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
